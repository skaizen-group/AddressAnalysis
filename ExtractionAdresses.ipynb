{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTATION DES LIBRAIRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des imports\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "import glob\n",
    "import string\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "print(\"Chargement des imports terminé...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONCTIONS DE PRE TRAITEMENT DES DONNEES D ADRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(doc):\n",
    "    doc2 = \"\"\n",
    "    bol = 1\n",
    "    for i in doc:\n",
    "        string = ' '.join(i.text.split())\n",
    "        if string != '':\n",
    "            if bol:\n",
    "                bol = 0\n",
    "            else:\n",
    "                doc2 += ' '\n",
    "            doc2 += (string)\n",
    "    \n",
    "    return nlp.make_doc(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newLine(doc):\n",
    "    doc2 = \"\"\n",
    "    tabNL = []\n",
    "    tabNomLieu = [\"batiment\",\"residence\",\"immeuble\",\"zone\"]\n",
    "    tabNL.extend(tabNomLieu)\n",
    "    tabType = ['cp','bp','tsa']\n",
    "    tabNL.extend(tabType)\n",
    "    tabComplement = ['bureau','appartement','couloir','escalier',\"entree\"]\n",
    "    tabNL.extend(tabComplement)\n",
    "    tabCedex = ['cedex']\n",
    "    tabNL.extend(tabCedex)\n",
    "    \n",
    "    for i in doc:\n",
    "        if ( i.text[0].isdigit()):\n",
    "            if( doc[i.i-1].text.lower() not in tabNL ):\n",
    "                doc2 += \"\\n\"\n",
    "        if ( i.text.lower() in tabNL ) :\n",
    "\n",
    "            doc2 += \"\\n\"\n",
    "        doc2 += i.text+' '\n",
    "        \n",
    "    tabSplit = doc2.split('\\n')\n",
    "    bol = 1 \n",
    "    \n",
    "    while ( bol == 1):\n",
    "        bol = 0\n",
    "        idx = -1\n",
    "        \n",
    "        for index, line in enumerate(tabSplit):\n",
    "            firstWord = line.split(' ')[0].lower()\n",
    "            if firstWord in tabComplement:\n",
    "                idx = index\n",
    "            if firstWord in tabNomLieu and idx != -1 :\n",
    "                tmp = tabSplit[idx]\n",
    "                tabSplit[idx] = line\n",
    "                tabSplit[index] = tmp\n",
    "         \n",
    "                bol = 1\n",
    "\n",
    "    doc2 = '\\n'.join(tabSplit)\n",
    "        \n",
    "    return nlp.make_doc(doc2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISATION DU MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du modèle \n",
    "\n",
    "nlp = spacy.blank(\"fr\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "nlp.add_pipe(preproc, first=True)\n",
    "nlp.add_pipe(newLine, after='preproc')\n",
    "#Variable d'entrainement du modèle\n",
    "\n",
    "TRAINING_DATA_text=[]\n",
    "TRAINING_DATA_ann=[]\n",
    "tabLabel=[]\n",
    "nbFile=0    \n",
    "\n",
    "print(\"Modèle initialisé...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ajoute tout les labels présent dans le modèle\n",
    "\n",
    "tabLabel = [\"Sexe\",\"Prenom\",\"Nom\",\"Role\",\"nomLieu\",\"noRue\",\"nomRue\",\"CodePostal\",\"Ville\",\"Cedex\",\"Type\",\"Pays\",\"complementRue\",\"Identification\",\"Service\",\"etage\"]\n",
    "    \n",
    "#On ajoute les labels au modèle\n",
    "for label in tabLabel:\n",
    "    ner.add_label(label)\n",
    "\n",
    "print(\"Tableau de labels initialisé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHARGEMENT DES DONNES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbLineMax = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DATA_Adresse/adresse_paris.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    BldgNbTab=[None]*nbLineMax\n",
    "    StrtNmTab=[None]*nbLineMax\n",
    "    \n",
    "    nb=0\n",
    "    for d in range(nbLineMax):\n",
    "        adr = data[d]['fields']['l_adr']\n",
    "        BldgNbTab[d],StrtNmTab[d] = adr.split(' ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villes = []\n",
    "with open('DATA_Adresse/villes_france.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        villes.append(row[3])\n",
    "        \n",
    "random.shuffle(villes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "entrepriseCSV = []\n",
    "with open('DATA_Adresse/entreprises.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    for row in csv_reader:\n",
    "        entrepriseCSV.append(row)\n",
    "        \n",
    "random.shuffle(entrepriseCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabServices = ['Service commercial','Département marketing','Direction financière','Service industriel','Département des ressources humaines']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traitement des chaines de caractères**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On choisi la casse d'une chaine de caractère au hasard, par exemple si on a : texte = 'Exemple'\n",
    "def transfName(texte):\n",
    "    rdm = random.choice([1,2,3,4])\n",
    "\n",
    "    if rdm == 1 :\n",
    "        texte = texte.upper() # texte -> EXEMPLE ( majuscule )\n",
    "    elif rdm == 2 :\n",
    "        texte = texte.lower() # texte -> exemple ( miniscule )\n",
    "    elif rdm == 3 :\n",
    "        texte = texte[0].upper() + texte[1:len(texte)].lower() #texte -> Exemple ( nom propres )\n",
    "        \n",
    "    return texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONCTION DE GENERATION D'ADRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_AdresseProfessionel():\n",
    "    adresse = \"\"\n",
    "    TRAINING_DATA_ann={}\n",
    "    TRAINING_DATA_ann['entities']= []\n",
    "    \n",
    "    #Texte aléatoire ou intègrera l'adresse entre les lignes 0 et 4\n",
    "    allchar = string.ascii_letters+ string.digits+\" \"\n",
    "\n",
    "    randEntreprise = int(random.random()*len(entrepriseCSV))\n",
    "    entreprise = entrepriseCSV[randEntreprise]\n",
    "    \n",
    "    #identification\n",
    "    \n",
    "    identification = entreprise[0]\n",
    "    adresse += transfName(identification)\n",
    "    TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(identification),len(adresse),\"Identification\"])  \n",
    "    \n",
    "    #Service\n",
    "    \n",
    "    service = random.choice(tabServices)\n",
    "    adresse += ' '+transfName(service)\n",
    "    TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(service),len(adresse),\"Service\"])  \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Nom du Lieu    \n",
    "    if(random.random()>0.4):\n",
    "        #randNomLieu1 = int(random.random()*2+2)\n",
    "        randNomLieu2 = int(random.random()*4 + 4)\n",
    "        nomLieu1 = random.choice([\"Batiment\",\"Residence\",\"Immeuble\",\"Zone Industrielle\"])\n",
    "        nomLieu2 = ''.join([random.choice( string.ascii_letters + ' ' ) for n in range(randNomLieu2)])\n",
    "        nomLieu = nomLieu1+\" \"+nomLieu2\n",
    "        adresse += \"\\n\"+transfName(nomLieu)\n",
    "        TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(nomLieu),len(adresse),\"nomLieu\"])  \n",
    "    \n",
    "    \n",
    "    #Nom du Lieu    \n",
    "    if(random.random()>0.4):\n",
    "        #randNomLieu1 = int(random.random()*2+2)\n",
    "        etage2 = int(random.random()*1 + 20)\n",
    "        etage1 = random.choice([\"e\",\"er\",\"eme\"])\n",
    "        etage = str(etage2)+etage1+\" étage\"\n",
    "        adresse += \"\\n\"+transfName(etage)\n",
    "        TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(etage),len(adresse),\"etage\"])  \n",
    "    \n",
    "    #Nom du Lieu    \n",
    "    for i in range( random.choice([1,2]) ):\n",
    "        if(random.random()>0.4):\n",
    "            #randNomLieu1 = int(random.random()*2+2)\n",
    "            if ( random.random() > 0.5 ):\n",
    "                complementRue2 = int(random.random()*399 + 1)\n",
    "            else :\n",
    "                complementRue2 = random.choice( string.ascii_uppercase ) \n",
    "            \n",
    "            complementRue1 = random.choice([\"Appartement\",\"Bureau\",'couloir','escalier',\"entree\"])\n",
    "            complementRue = complementRue1+\" \"+str(complementRue2)\n",
    "            adresse += \"\\n\"+transfName(complementRue)\n",
    "            TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(complementRue),len(adresse),\"complementRue\"])  \n",
    "    \n",
    "    try:\n",
    "        noRue,nomRue = entreprise[6].split(' ',1)\n",
    "    except ValueError as e:\n",
    "        noRue,nomRue = entrepriseCSV[0][6].split(' ',1)\n",
    "        \n",
    "    if nomRue[0] == ' ':\n",
    "        nomRue = nomRue[1:]\n",
    "    \n",
    "    adresse += \"\\n{}\".format(noRue)\n",
    "    TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len('{}'.format(noRue)),len(adresse),\"noRue\"]) \n",
    "    \n",
    "    if( random.random() > 0.5 ) :\n",
    "        adresse += \", \"\n",
    "        \n",
    "    adresse += \" \"+nomRue\n",
    "    TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(nomRue),len(adresse),\"nomRue\"])  \n",
    "    \n",
    "\n",
    "    if(random.random() > 0.5):\n",
    "        tabTypeAdresse = [\"BP\",\"CP\",\"TSA\"]\n",
    "        typeAdresse = random.choice(tabTypeAdresse)+\" {}\".format( int(random.random()*9999+1) )\n",
    "        adresse += \"\\n\"+typeAdresse\n",
    "        TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(typeAdresse),len(adresse),\"Type\"]) \n",
    "    \n",
    "    randCodePostal = entreprise[7]\n",
    "    adresse += \"\\n{}\".format(randCodePostal)\n",
    "    TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len('{}'.format(randCodePostal)),len(adresse),\"CodePostal\"]) \n",
    "    \n",
    "    \n",
    "    ville = entreprise[8]\n",
    "    adresse += \" \"+transfName(ville)\n",
    "    TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(ville),len(adresse),\"Ville\"]) \n",
    "    \n",
    "    if(random.random()>0.5):\n",
    "        Cedex = \"Cedex {}\".format( int(random.random()*98+1) )\n",
    "        adresse += \"\\n\"+Cedex\n",
    "        TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(Cedex),len(adresse),\"Cedex\"])  \n",
    "\n",
    "    if(random.random()>0.5):\n",
    "        Pays = \"France\"\n",
    "        adresse += \"\\n\"+Pays\n",
    "        TRAINING_DATA_ann.get(\"entities\").append([len(adresse)-len(Pays),len(adresse),\"Pays\"])  \n",
    "    \n",
    "    return [adresse,TRAINING_DATA_ann]\n",
    "\n",
    "print(\"Fonction créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATION D'UN NOMBRE n D'ADRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_text=[]\n",
    "TRAINING_DATA_ann=[]\n",
    "\n",
    "nAdresse = 200\n",
    "\n",
    "for i in range(nAdresse):\n",
    "\n",
    "    [adresse,entite] = gen_AdresseProfessionel()\n",
    "    \n",
    "    TRAINING_DATA_text.append(adresse)\n",
    "    TRAINING_DATA_ann.append(entite)\n",
    "    \n",
    "print(\"Variable d'entrainement initialisée !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRAINEMENT DU MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.begin_training()\n",
    "#On réentraine le modèle 600 : 80\n",
    "for itn in range(75):\n",
    "    losses = {}\n",
    "    nlp.update(TRAINING_DATA_text, TRAINING_DATA_ann, losses=losses)\n",
    "    \n",
    "print(\"Entrainement fini avec un taux de perte à {}\".format(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sauvegarde du modèle sur le disque**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enregistre le modèle sur le disque \n",
    "with nlp.disable_pipes('preproc', 'newLine'):\n",
    "    nlp.to_disk('Model/Modele_8Jan')\n",
    "\n",
    "print(\"Modèle sauvegardé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sauvegarde des adresses sur le disque**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TRAINING_DATA_text)):\n",
    "    \n",
    "    f = open(\"/home/hamza/Notebook/Courrier/TextAnn/adresse\"+'{}'.format(i)+\".txt\",\"w+\")\n",
    "    f.write(TRAINING_DATA_text[i])\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sauvegarde des annotations d'adresses sur le disque**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TRAINING_DATA_ann)):\n",
    "    f = open(\"/home/hamza/Notebook/Courrier/TextAnn/adresse\"+'{}'.format(i)+\".ann\",\"w+\")\n",
    "    for j in range(len(TRAINING_DATA_ann[i]['entities'])):\n",
    "\n",
    "        debutEntite = TRAINING_DATA_ann[i]['entities'][j][0]\n",
    "        finEntite = TRAINING_DATA_ann[i]['entities'][j][1]\n",
    "        nomEntite = TRAINING_DATA_ann[i]['entities'][j][2]\n",
    "        \n",
    "        chaine = \"T{} {} {} {} \\n\".format((j+1),nomEntite,debutEntite,finEntite)\n",
    "        f.write(chaine)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JEUX D'ESSAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On la transforme en texte\n",
    "texte =  gen_AdresseProfessionel()[0]\n",
    "\n",
    "#On donne le texte au modèle\n",
    "doc = nlp(texte)\n",
    "\n",
    "print(\"Texte : \\n\")\n",
    "print(texte)\n",
    "print()\n",
    "print(\"Formatage du texte : \\n\")\n",
    "\n",
    "#On affiche le résultat de la prédiction\n",
    "print(doc)\n",
    "print()\n",
    "print(\"Prédiction : \\n\")\n",
    "for entity in doc.ents:\n",
    "    print(entity.label_, ' | ', entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texte2 = \"\"\"DURAND SA\n",
    "SERVICE ACHAT\n",
    "ZONE INDUSTRIELLE OUEST\n",
    "25 RUE DES FLEURS\n",
    "33500 LIBOURNE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#On donne le texte au modèle\n",
    "doc = nlp(texte2)\n",
    "\n",
    "print(\"Texte : \\n\")\n",
    "print(texte2)\n",
    "print()\n",
    "print(\"Formatage du texte : \\n\")\n",
    "\n",
    "#On affiche le résultat de la prédiction\n",
    "print(doc)\n",
    "print()\n",
    "print(\"Prédiction : \\n\")\n",
    "for entity in doc.ents:\n",
    "    print(entity.label_, ' | ', entity.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
